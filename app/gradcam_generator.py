import tensorflow as tf
from tensorflow import keras
import numpy as np
import cv2
import os
import json
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class GradCAMGenerator:
    """
    ğŸ“ Grad-CAM: Shows what the model focuses on in images
    """
    
    def __init__(self, model, class_names, img_size=(256, 256)):
        self.model = model
        self.class_names = class_names
        self.img_size = img_size
        self.num_classes = len(class_names)
    
    def load_and_preprocess_image(self, image_path):
        """
        ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
        """
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
            img = keras.preprocessing.image.load_img(
                image_path, 
                target_size=self.img_size
            )
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ array
            img_array = keras.preprocessing.image.img_to_array(img)
            img_array = np.expand_dims(img_array, axis=0)
            
            # ØªØ·Ø¨ÙŠØ¹ (Ù…Ø¹Ø§ÙŠÙŠØ± EfficientNetV2)
            img_preprocessed = tf.keras.applications.efficientnet_v2.preprocess_input(
                img_array.copy()
            )
            
            return img_array, img_preprocessed
        except Exception as e:
            logger.error(f"Error loading image {image_path}: {str(e)}")
            return None, None
    
    def make_gradcam_heatmap(self, img_preprocessed, pred_class_idx):
        """
        Ø­Ø³Ø§Ø¨ Grad-CAM heatmap - Ø·Ø±ÙŠÙ‚Ø© Ù…Ø¨Ø³Ø·Ø© ØªØ¹Ù…Ù„ Ù…Ø¹ Rescaling layer
        """
        try:
            # 1. Ø§Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙØ±Ø¹ÙŠ EfficientNet
            efficientnet_layer = None
            for layer in self.model.layers:
                if hasattr(layer, 'name') and 'efficientnet' in layer.name.lower():
                    efficientnet_layer = layer
                    logger.info(f"Found EfficientNet base model: {layer.name}")
                    break

            if efficientnet_layer is None:
                logger.warning("EfficientNet layer not found")
                return self._simple_saliency_map(img_preprocessed, pred_class_idx)

            # 2. Ø§Ø¨Ø­Ø« Ø¹Ù† Ø¢Ø®Ø± Ø·Ø¨Ù‚Ø© Conv Ø¯Ø§Ø®Ù„ EfficientNet
            target_layer_name = None
            target_layers = ['top_conv', 'block7a_project_conv', 'block6a_expand_conv']
            for layer_name in target_layers:
                try:
                    efficientnet_layer.get_layer(layer_name)
                    target_layer_name = layer_name
                    logger.info(f"Found target conv layer: {layer_name}")
                    break
                except:
                    continue

            if target_layer_name is None:
                logger.warning("No suitable conv layer found")
                return self._simple_saliency_map(img_preprocessed, pred_class_idx)

            # 3. Ø¥Ù†Ø´Ø§Ø¡ grad_model - Ø§Ù„Ø¢Ù† ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ¹Ù…Ù„ Ù„Ø£Ù† rescaling layer Ø¨Ø³ÙŠØ·Ø©
            try:
                # Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ output Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©
                conv_layer_output = efficientnet_layer.get_layer(target_layer_name).output

                grad_model = keras.Model(
                    inputs=self.model.input,
                    outputs=[conv_layer_output, self.model.output]
                )
                logger.info("Grad-CAM model created successfully")

            except Exception as e:
                logger.error(f"Could not create grad_model: {str(e)}")
                return self._simple_saliency_map(img_preprocessed, pred_class_idx)

            # 4. Ø­Ø³Ø§Ø¨ Gradients
            with tf.GradientTape() as tape:
                conv_outputs, predictions = grad_model(img_preprocessed, training=False)
                class_channel = predictions[:, pred_class_idx]

            grads = tape.gradient(class_channel, conv_outputs)

            if grads is None:
                logger.warning("Gradients are None")
                return self._simple_saliency_map(img_preprocessed, pred_class_idx)

            # 5. Ø­Ø³Ø§Ø¨ Grad-CAM heatmap
            pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
            conv_output = conv_outputs[0]
            heatmap = conv_output @ pooled_grads[..., tf.newaxis]
            heatmap = tf.squeeze(heatmap)
            heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-10)

            logger.info("âœ… Grad-CAM heatmap computed successfully!")
            return heatmap.numpy()

        except Exception as e:
            logger.error(f"Error in Grad-CAM: {str(e)}")
            return self._simple_saliency_map(img_preprocessed, pred_class_idx)
    
    def _simple_saliency_map(self, img_preprocessed, pred_class_idx):
        """
        Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø¯ÙŠÙ„Ø©: Saliency map Ø¨Ø³ÙŠØ·Ø©
        """
        try:
            with tf.GradientTape() as tape:
                img_tensor = tf.cast(img_preprocessed, tf.float32)
                tape.watch(img_tensor)
                predictions = self.model(img_tensor, training=False)
                class_channel = predictions[:, pred_class_idx]
            
            grads = tape.gradient(class_channel, img_tensor)
            saliency = tf.reduce_max(tf.abs(grads), axis=-1)
            saliency = saliency[0]
            saliency = (saliency - tf.reduce_min(saliency)) / (tf.reduce_max(saliency) - tf.reduce_min(saliency) + 1e-10)
            
            return saliency.numpy()
        except Exception as e:
            logger.error(f"Error in saliency map: {str(e)}")
            # Ø¥Ø±Ø¬Ø¹ Ø®Ø±ÙŠØ·Ø© Ø³ÙˆØ¯Ø§Ø¡ ÙÙŠ Ø£Ø³ÙˆØ£ Ø§Ù„Ø­Ø§Ù„Ø§Øª
            return np.zeros((self.img_size[0], self.img_size[1]))
    
    def process_image(self, image_path):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒØ§Ù…Ù„Ø© Ù„ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø©
        """
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
            img_array, img_preprocessed = self.load_and_preprocess_image(image_path)
            
            if img_array is None:
                return None
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤
            preds = self.model.predict(img_preprocessed, verbose=0)[0]
            pred_class_idx = np.argmax(preds)
            confidence = preds[pred_class_idx]
            
            # Ø­Ø³Ø§Ø¨ Grad-CAM
            heatmap = self.make_gradcam_heatmap(img_preprocessed, pred_class_idx)
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            original_img = keras.preprocessing.image.load_img(image_path)
            original_array = keras.preprocessing.image.img_to_array(original_img) / 255.0
            
            # ØªÙƒØ¨ÙŠØ± heatmap
            heatmap_resized = cv2.resize(
                heatmap, 
                (original_array.shape[1], original_array.shape[0])
            )
            
            # ØªÙ„ÙˆÙŠÙ† heatmap
            heatmap_colored = cv2.applyColorMap(
                np.uint8(255 * heatmap_resized), 
                cv2.COLORMAP_JET
            )
            heatmap_colored = heatmap_colored / 255.0
            
            # Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØ±
            overlay = original_array * 0.5 + heatmap_colored * 0.5
            
            return {
                'original': original_array,
                'heatmap': heatmap_resized,
                'overlay': overlay,
                'predictions': preds,
                'pred_class_idx': int(pred_class_idx),
                'confidence': float(confidence),
                'class_name': self.class_names[pred_class_idx]
            }
        
        except Exception as e:
            logger.error(f"Error processing image {image_path}: {str(e)}")
            return None
    
    def convert_to_base64(self, img_array):
        """
        ØªØ­ÙˆÙŠÙ„ ØµÙˆØ±Ø© numpy Ø¥Ù„Ù‰ base64 Ù„Ù„Ù€ JSON
        """
        try:
            import base64
            from io import BytesIO
            from PIL import Image
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ uint8
            img_uint8 = np.uint8(img_array * 255)
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØµÙˆØ±Ø© PIL
            pil_img = Image.fromarray(img_uint8)
            
            # Ø­ÙØ¸ ÙÙŠ BytesIO
            buffer = BytesIO()
            pil_img.save(buffer, format='JPEG', quality=85)
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ base64
            img_base64 = base64.b64encode(buffer.getvalue()).decode()
            
            return f"data:image/jpeg;base64,{img_base64}"
        
        except Exception as e:
            logger.error(f"Error converting to base64: {str(e)}")
            return None
    
    def generate_gradcam_samples(self, image_paths, output_dir):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© ØµÙˆØ± ÙˆØ­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        """
        try:
            results = []
            
            for idx, img_path in enumerate(image_paths):
                logger.info(f"Processing image {idx + 1}/{len(image_paths)}: {os.path.basename(img_path)}")
                
                result = self.process_image(img_path)
                
                if result is None:
                    logger.warning(f"Failed to process {img_path}")
                    continue
                
                # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ base64
                result['original_base64'] = self.convert_to_base64(result['original'])
                result['heatmap_base64'] = self.convert_to_base64(
                    cv2.applyColorMap(np.uint8(255 * result['heatmap']), cv2.COLORMAP_JET) / 255.0
                )
                result['overlay_base64'] = self.convert_to_base64(result['overlay'])
                
                # Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (arrays)
                del result['original']
                del result['heatmap']
                del result['overlay']
                
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
                result['all_predictions'] = {
                    self.class_names[i]: float(result['predictions'][i]) 
                    for i in range(len(self.class_names))
                }
                del result['predictions']
                
                results.append(result)
            
            # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            os.makedirs(output_dir, exist_ok=True)
            
            output_data = {
                'generated_at': datetime.now().isoformat(),
                'num_samples': len(results),
                'samples': results
            }
            
            json_path = os.path.join(output_dir, 'gradcam_data.json')
            with open(json_path, 'w') as f:
                json.dump(output_data, f, indent=2)
            
            logger.info(f"Saved {len(results)} samples to {json_path}")
            
            return output_data
        
        except Exception as e:
            logger.error(f"Error generating Grad-CAM samples: {str(e)}")
            return None