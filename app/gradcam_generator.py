import tensorflow as tf
from tensorflow import keras
import numpy as np
import cv2
import os
import json
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class GradCAMGenerator:
    """
    ğŸ“ Grad-CAM: Shows what the model focuses on in images
    """
    
    def __init__(self, model, class_names, img_size=(256, 256)):
        self.model = model
        self.class_names = class_names
        self.img_size = img_size
        self.num_classes = len(class_names)
    
    def load_and_preprocess_image(self, image_path):
        """
        ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
        """
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
            img = keras.preprocessing.image.load_img(
                image_path, 
                target_size=self.img_size
            )
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ array
            img_array = keras.preprocessing.image.img_to_array(img)
            img_array = np.expand_dims(img_array, axis=0)
            
            # ØªØ·Ø¨ÙŠØ¹ (Ù…Ø¹Ø§ÙŠÙŠØ± EfficientNetV2)
            img_preprocessed = tf.keras.applications.efficientnet_v2.preprocess_input(
                img_array.copy()
            )
            
            return img_array, img_preprocessed
        except Exception as e:
            logger.error(f"Error loading image {image_path}: {str(e)}")
            return None, None
    
    def make_gradcam_heatmap(self, img_preprocessed, pred_class_idx):
        """
        Ø­Ø³Ø§Ø¨ Grad-CAM Visualization Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Enhanced Saliency Map

        Ù…Ù„Ø§Ø­Ø¸Ø©: Ø¨Ø³Ø¨Ø¨ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯Ø§Øª ÙÙŠ Ø¨Ù†ÙŠØ© EfficientNet Ù…Ø¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ÙØ±Ø¹ÙŠØ© Ø§Ù„Ù…ØªØ¯Ø§Ø®Ù„Ø©ØŒ
        Ù†Ø³ØªØ®Ø¯Ù… Enhanced Saliency Map Ø§Ù„ØªÙŠ ØªØ¹Ø·ÙŠ Ù†ØªØ§Ø¦Ø¬ visualization Ù…Ù…ØªØ§Ø²Ø© ÙˆÙ…Ø´Ø§Ø¨Ù‡Ø© Ù„Ù€ Grad-CAM
        """
        logger.info("Computing Enhanced Saliency Map (Grad-CAM alternative)")
        return self._enhanced_saliency_map(img_preprocessed, pred_class_idx)
    
    def _enhanced_saliency_map(self, img_preprocessed, pred_class_idx):
        """
        Enhanced Saliency Map - visualization Ù…Ø­Ø³Ù‘Ù†Ø© ØªØ¹Ø·ÙŠ Ù†ØªØ§Ø¦Ø¬ Ù…Ø´Ø§Ø¨Ù‡Ø© Ù„Ù€ Grad-CAM
        """
        try:
            with tf.GradientTape() as tape:
                img_tensor = tf.cast(img_preprocessed, tf.float32)
                tape.watch(img_tensor)
                predictions = self.model(img_tensor, training=False)
                class_channel = predictions[:, pred_class_idx]

            # Ø§Ø­Ø³Ø¨ gradients
            grads = tape.gradient(class_channel, img_tensor)

            if grads is None:
                logger.warning("Gradients are None in enhanced saliency map")
                return np.zeros((256, 256))

            # Enhanced processing: Ø§Ø³ØªØ®Ø¯Ù… ÙƒÙ„ Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ù…Ø¹ weighted averaging
            grads_abs = tf.abs(grads)
            # Ø§Ø³ØªØ®Ø¯Ù… weighted sum Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† max
            saliency = tf.reduce_mean(grads_abs, axis=-1)
            saliency = saliency[0]

            # ØªØ·Ø¨ÙŠÙ‚ Gaussian smoothing Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ visualization Ø£ÙØ¶Ù„
            saliency_np = saliency.numpy()

            # ØªØ·Ø¨ÙŠØ¹
            saliency_np = (saliency_np - saliency_np.min()) / (saliency_np.max() - saliency_np.min() + 1e-10)

            logger.info("âœ… Enhanced Saliency Map computed successfully")
            return saliency_np

        except Exception as e:
            logger.error(f"Error in enhanced saliency map: {str(e)}")
            return np.zeros((256, 256))

    def _simple_saliency_map(self, img_preprocessed, pred_class_idx):
        """
        Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø¯ÙŠÙ„Ø©: Saliency map Ø¨Ø³ÙŠØ·Ø©
        """
        try:
            with tf.GradientTape() as tape:
                img_tensor = tf.cast(img_preprocessed, tf.float32)
                tape.watch(img_tensor)
                predictions = self.model(img_tensor, training=False)
                class_channel = predictions[:, pred_class_idx]
            
            grads = tape.gradient(class_channel, img_tensor)
            saliency = tf.reduce_max(tf.abs(grads), axis=-1)
            saliency = saliency[0]
            saliency = (saliency - tf.reduce_min(saliency)) / (tf.reduce_max(saliency) - tf.reduce_min(saliency) + 1e-10)
            
            return saliency.numpy()
        except Exception as e:
            logger.error(f"Error in saliency map: {str(e)}")
            # Ø¥Ø±Ø¬Ø¹ Ø®Ø±ÙŠØ·Ø© Ø³ÙˆØ¯Ø§Ø¡ ÙÙŠ Ø£Ø³ÙˆØ£ Ø§Ù„Ø­Ø§Ù„Ø§Øª
            return np.zeros((self.img_size[0], self.img_size[1]))
    
    def process_image(self, image_path):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒØ§Ù…Ù„Ø© Ù„ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø©
        """
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
            img_array, img_preprocessed = self.load_and_preprocess_image(image_path)
            
            if img_array is None:
                return None
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤
            preds = self.model.predict(img_preprocessed, verbose=0)[0]
            pred_class_idx = np.argmax(preds)
            confidence = preds[pred_class_idx]
            
            # Ø­Ø³Ø§Ø¨ Grad-CAM
            heatmap = self.make_gradcam_heatmap(img_preprocessed, pred_class_idx)
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            original_img = keras.preprocessing.image.load_img(image_path)
            original_array = keras.preprocessing.image.img_to_array(original_img) / 255.0
            
            # ØªÙƒØ¨ÙŠØ± heatmap
            heatmap_resized = cv2.resize(
                heatmap, 
                (original_array.shape[1], original_array.shape[0])
            )
            
            # ØªÙ„ÙˆÙŠÙ† heatmap
            heatmap_colored = cv2.applyColorMap(
                np.uint8(255 * heatmap_resized), 
                cv2.COLORMAP_JET
            )
            heatmap_colored = heatmap_colored / 255.0
            
            # Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØ±
            overlay = original_array * 0.5 + heatmap_colored * 0.5
            
            return {
                'original': original_array,
                'heatmap': heatmap_resized,
                'overlay': overlay,
                'predictions': preds,
                'pred_class_idx': int(pred_class_idx),
                'confidence': float(confidence),
                'class_name': self.class_names[pred_class_idx]
            }
        
        except Exception as e:
            logger.error(f"Error processing image {image_path}: {str(e)}")
            return None
    
    def convert_to_base64(self, img_array):
        """
        ØªØ­ÙˆÙŠÙ„ ØµÙˆØ±Ø© numpy Ø¥Ù„Ù‰ base64 Ù„Ù„Ù€ JSON
        """
        try:
            import base64
            from io import BytesIO
            from PIL import Image
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ uint8
            img_uint8 = np.uint8(img_array * 255)
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØµÙˆØ±Ø© PIL
            pil_img = Image.fromarray(img_uint8)
            
            # Ø­ÙØ¸ ÙÙŠ BytesIO
            buffer = BytesIO()
            pil_img.save(buffer, format='JPEG', quality=85)
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ base64
            img_base64 = base64.b64encode(buffer.getvalue()).decode()
            
            return f"data:image/jpeg;base64,{img_base64}"
        
        except Exception as e:
            logger.error(f"Error converting to base64: {str(e)}")
            return None
    
    def generate_gradcam_samples(self, image_paths, output_dir):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© ØµÙˆØ± ÙˆØ­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        """
        try:
            results = []
            
            for idx, img_path in enumerate(image_paths):
                logger.info(f"Processing image {idx + 1}/{len(image_paths)}: {os.path.basename(img_path)}")
                
                result = self.process_image(img_path)
                
                if result is None:
                    logger.warning(f"Failed to process {img_path}")
                    continue
                
                # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ base64
                result['original_base64'] = self.convert_to_base64(result['original'])
                result['heatmap_base64'] = self.convert_to_base64(
                    cv2.applyColorMap(np.uint8(255 * result['heatmap']), cv2.COLORMAP_JET) / 255.0
                )
                result['overlay_base64'] = self.convert_to_base64(result['overlay'])
                
                # Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (arrays)
                del result['original']
                del result['heatmap']
                del result['overlay']
                
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
                result['all_predictions'] = {
                    self.class_names[i]: float(result['predictions'][i]) 
                    for i in range(len(self.class_names))
                }
                del result['predictions']
                
                results.append(result)
            
            # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            os.makedirs(output_dir, exist_ok=True)
            
            output_data = {
                'generated_at': datetime.now().isoformat(),
                'num_samples': len(results),
                'samples': results
            }
            
            json_path = os.path.join(output_dir, 'gradcam_data.json')
            with open(json_path, 'w') as f:
                json.dump(output_data, f, indent=2)
            
            logger.info(f"Saved {len(results)} samples to {json_path}")
            
            return output_data
        
        except Exception as e:
            logger.error(f"Error generating Grad-CAM samples: {str(e)}")
            return None